README for folder Tokenize

Contains rules and scripts for tokenizing text files.

subfolders

FileSources -- put files to be tokenized here

CollectionMetadata -- stores backups of metadata for the whole collection

LoadingMetadata -- this is also where you put metadata for the files to be tokenized

Rules -- stores FusingRules, HyphenRules, SyncopeRules, Dictionary, VariantSpellings.

Scripts -- stores the Tokenizer Script

Output -- here is where the tokenized sparse table goes, also the new metadata files produced by merging Collection & Loading Metadata.